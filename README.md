# # ðŸ“œ Poetry Creativity Evaluation (LLM vs Human)

This project evaluates the **creative quality of poetry** generated by large language models (LLMs) by comparing them with human-written poems using **semantic similarity graphs** and **GPT-4o originality scoring**.

The analysis includes:
- Sentence embedding comparisons using `all-MiniLM-L6-v2`
- Graph-based creativity scoring
- GPT-4o originality judgment (1â€“10 scale)
- Correlation plots and interpretability analyses

---

## ðŸ“‚ Files & Descriptions

### `poetry_creativity_graph.py`
- Builds a bipartite similarity graph between LLM and human poems.
- Computes the graph-based creativity score:
  \[
  \text{Creativity}_{1â€“10} = 1 + 9 \cdot (1 - \text{avg similarity})
  \]
- Output: `LLM_Poems_Creativity_Scored_topk.csv`, `LLM_Poems_Creativity_Scored_AvgSim_1to10.csv`

---

### `poetry_visualizations.py`
- Generates:
  - Barplot of average scores by model
  - Scatterplot (GPT-4o originality vs graph-based score)
  - Correlation heatmap

---

### `All_Poems_Originality_Scored.csv`
- Merged file of:
  - 140 human-authored poems (pre-2018)
  - 240 LLM-generated poems from ChatGPT-4o, Gemini, Mistral, LLAMA
- Includes theme, title, source, poem text, and GPT-4o originality score.

---

### `LLM_Poems_Creativity_Scored_topk.csv`
- Creativity scores computed using **maximum similarity** to top-3 human poems.

### `LLM_Poems_Creativity_Scored_AvgSim_1to10.csv`
- Final creativity score on 1â€“10 scale using **average similarity** to top-5 nearest human poems.

---

## ðŸ“Š Output Visualizations

- **Mean Score by Model:** Average creativity and originality per model
- **Scatterplot:** Comparison between GPT-4o and graph-based scores per poem
- **Correlation Heatmap:** Score correlation across metrics

---

## ðŸ§ª Requirements

Install dependencies using:

```bash
pip install pandas numpy scikit-learn sentence-transformers networkx matplotlib seaborn


Please go to the respective folders for each benchmark to test